{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_urls = {\n",
    "    \"APC\": \"https://approcess.com/careers\",\n",
    "    \"Abbvie\": \"https://careers.abbvie.com/en/jobs?q=&options=&page=1&la=53.3498053&lo=-6.2603097&ln=Dublin,%20Ireland&lr=100\",\n",
    "    \"Astrazeneca\": \"https://careers.astrazeneca.com/location/ireland-jobs/7684/2963597/2\",\n",
    "    \"Pfizer\": \"https://pfizer.wd1.myworkdayjobs.com/en-US/PfizerCareers?Location_Country=04a05835925f45b3a59406a2a6b72c8a&locations=e2d3979e3af101cb6c9c1a59076c3890\",\n",
    "    \"BMS\": \"https://jobs.bms.com/careers?location=ireland\",\n",
    "    \"MSD\": \"https://jobs.msd.com/gb/en/ireland-job-search?utm_source=google&utm_medium=sea&utm_campaign=emea-ie&utm_content=branded&gclid=CjwKCAjwodC2BhAHEiwAE67hJBtaWGHg5w7tWTOeXFukL141m02EHQ2NEu7zg4139IxtTg1M7wxPsRoC9JcQAvD_BwE\",\n",
    "    \"Takeda\": \"https://jobs.takeda.com/search-jobs/Ireland/1113/2/2963597/53/-8/50/2\",\n",
    "    \"Amgen\": \"https://www.amgen.jobs/irl/jobs/\",\n",
    "    \"Vle therapeutics\": \"https://www.vletherapeutics.com/careers\",\n",
    "    \"Astellas\": \"https://astellas.avature.net/en_GB/careers/SearchJobs/?1329=%5B180801%5D&1329_format=1348&listFilterMode=1&jobOffset=\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def APC():\n",
    "    try:\n",
    "        response = requests.get(company_urls[\"APC\"])\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.content,'lxml')\n",
    "        table = soup.find('table')\n",
    "        rows = table.find_all('tr')[1:]\n",
    "        job_details = []\n",
    "        for row in rows:\n",
    "            title = row.find('td',class_='title title--quaternary').text.strip()\n",
    "            closing_date = row.find('td',class_='title title--senary').text.strip()\n",
    "            link = row.find('a')['href']\n",
    "            job_details.append({\n",
    "                'company':'APC',\n",
    "                'title':title,\n",
    "                'application link':link,\n",
    "                'closing_date':closing_date,\n",
    "                'job portal link':company_urls['APC']\n",
    "            })\n",
    "        return job_details\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching job details: {e}\")\n",
    "        return []\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Abbvie():\n",
    "    try:\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "        }\n",
    "        response = requests.get(company_urls['Abbvie'],headers=headers)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.content, 'lxml')\n",
    "        job_tiles = soup.find_all('a', class_='attrax-vacancy-tile__title')\n",
    "        jobs = []\n",
    "        for tile in job_tiles:\n",
    "            job_title = tile.get_text(strip=True)\n",
    "            job_url = tile['href']\n",
    "            jobs.append({\n",
    "                'company':'Abbvie',\n",
    "                'title': job_title,\n",
    "                'application link': 'https://careers.abbvie.com'+job_url,\n",
    "                'job portal link':company_urls['Abbvie']\n",
    "                })\n",
    "        return jobs\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching job details: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Astrazeneca():\n",
    "    try:   \n",
    "        base_url = company_urls['Astrazeneca']\n",
    "        jobs = []\n",
    "        page=1\n",
    "        while True:\n",
    "            url=f'{base_url}/{page}'\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()\n",
    "            if response.status_code != 200:\n",
    "                break\n",
    "            soup = BeautifulSoup(response.content,'lxml')\n",
    "            job_tiles = soup.find_all('a',class_='search-results-link')\n",
    "            if not job_tiles:\n",
    "                break\n",
    "            for tile in job_tiles:\n",
    "                job_title = tile.text.strip().split('\\n')[0]\n",
    "                job_url = tile['href']\n",
    "                jobs.append({\n",
    "                    'company':'Astrazeneca',\n",
    "                    'title':job_title,\n",
    "                    'application url':'https://careers.astrazeneca.com/'+job_url,\n",
    "                    'job portal link': company_urls['Astrazeneca']\n",
    "                })\n",
    "            page+=1\n",
    "        return jobs\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching job details: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Takeda():\n",
    "    try:\n",
    "        response = requests.get(company_urls['Takeda'])\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.content, 'lxml')\n",
    "        job_links = soup.find_all('a', {'data-job-id': True})\n",
    "        jobs = []\n",
    "        for job in job_links:\n",
    "            try:\n",
    "                job_title = job.find('h2', class_='title').text.strip()\n",
    "            except AttributeError:\n",
    "                break\n",
    "            job_url = job['href']\n",
    "            jobs.append({\n",
    "                'company':'Takeda',\n",
    "                'title':job_title,\n",
    "                'application url':'https://jobs.takeda.com/'+job_url,\n",
    "                'job portal link':company_urls['Takeda']\n",
    "            })\n",
    "        return jobs\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching job details: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Amgen():\n",
    "    try:\n",
    "        response = requests.get(company_urls['Amgen'])\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.content, 'lxml')\n",
    "        job_links = soup.find_all('h4')\n",
    "        jobs = []\n",
    "        for job in job_links:\n",
    "            job_title = job.text.strip()\n",
    "            job_url = 'https://www.amgen.jobs/'+job.find('a')['href']\n",
    "            jobs.append({\n",
    "                'company':'Amgen',\n",
    "                'title':job_title,\n",
    "                'application url':job_url,\n",
    "                'job portal link':company_urls['Amgen']\n",
    "            })\n",
    "        return jobs\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching job details: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Vle():\n",
    "    try:\n",
    "        response = requests.get(company_urls['Vle therapeutics'])\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.content, 'lxml')\n",
    "        job_links = soup.find_all('div',class_='table-content')\n",
    "        jobs = []\n",
    "        for job in job_links:\n",
    "            job_title = job.find('p', class_='job-description').text.strip()\n",
    "            closing_date = job.find('p', class_='close-date').text.strip() if job.find('p', class_='close-date') else 'N/A'\n",
    "            job_url = job.find('a', class_='careers-link')['href']\n",
    "            jobs.append({\n",
    "                'company':'Vle therapeutics',\n",
    "                'title': job_title,\n",
    "                'closing_date': closing_date,\n",
    "                'application url': job_url,\n",
    "                'job portal link': company_urls['Vle therapeutics']\n",
    "            })\n",
    "        return jobs\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching job details: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Astellas():    \n",
    "    try:\n",
    "        base_url = company_urls['Astellas']\n",
    "        jobs = []\n",
    "        page = 0\n",
    "        while True:\n",
    "            url=f'{base_url}{page}'\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()\n",
    "            if response.status_code != 200:\n",
    "                break\n",
    "            soup = BeautifulSoup(response.content, 'lxml')\n",
    "            job_tiles = soup.find_all('h3', class_='article__header__text__title')\n",
    "            if not job_tiles:\n",
    "                break\n",
    "            for tile in job_tiles:\n",
    "                job_title = tile.text.strip()\n",
    "                job_url = tile.find('a')['href']\n",
    "                jobs.append({\n",
    "                    'company':'Astellas',\n",
    "                    'title':job_title,\n",
    "                    'application url':job_url,\n",
    "                    'job portal link':url\n",
    "                })\n",
    "            page+=10\n",
    "        return jobs\n",
    "    except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error fetching job details: {e}\")\n",
    "            return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_job_postings():\n",
    "    all_jobs = {}\n",
    "\n",
    "    \n",
    "    all_jobs[\"Abbvie\"] = Abbvie()\n",
    "    all_jobs[\"Amgen\"] = Amgen()\n",
    "    all_jobs[\"APC\"] = APC()\n",
    "    all_jobs['Astellas'] = Astellas()\n",
    "    all_jobs[\"Astrazeneca\"] = Astrazeneca()\n",
    "    all_jobs[\"Takeda\"] = Takeda()\n",
    "    all_jobs['Vle therapeutics'] = Vle()\n",
    "    \n",
    "\n",
    "    return all_jobs\n",
    "\n",
    "def load_previous_jobs(filename):\n",
    "    if os.path.exists(filename):\n",
    "        with open(filename, 'r') as f:\n",
    "            return json.load(f)\n",
    "    else:\n",
    "        return {}\n",
    "\n",
    "def find_new_jobs(previous_jobs, current_jobs):\n",
    "    new_jobs = {}\n",
    "    \n",
    "    for company, jobs in current_jobs.items():\n",
    "        if company not in previous_jobs:\n",
    "            new_jobs[company] = jobs\n",
    "        else:\n",
    "            previous_titles = {job[\"title\"] for job in previous_jobs[company]}\n",
    "            new_jobs_for_company = [job for job in jobs if job[\"title\"] not in previous_titles]\n",
    "            \n",
    "            if new_jobs_for_company:\n",
    "                new_jobs[company] = new_jobs_for_company\n",
    "    \n",
    "    return new_jobs\n",
    "\n",
    "def update_json_file(filename, current_jobs):\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(current_jobs, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def main():\n",
    "#     # Define the JSON file path\n",
    "#     json_file = \"jobs.json\"\n",
    "    \n",
    "#     # Get the current job postings from all companies\n",
    "#     current_jobs = get_all_job_postings()\n",
    "    \n",
    "#     # Load the previous job postings from the JSON file\n",
    "#     previous_jobs = load_previous_jobs(json_file)\n",
    "    \n",
    "#     # Identify new job postings\n",
    "#     new_jobs = find_new_jobs(previous_jobs, current_jobs)\n",
    "    \n",
    "#     # Print new jobs\n",
    "#     if new_jobs:\n",
    "#         print(\"New job postings found:\")\n",
    "#         for company, jobs in new_jobs.items():\n",
    "#             print(f\"\\n{company}:\")\n",
    "#             for job in jobs:\n",
    "#                 print(job)\n",
    "#     else:\n",
    "#         print(\"No new job postings found.\")\n",
    "    \n",
    "#     # Update the JSON file with the current job postings\n",
    "#     update_json_file(json_file, current_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import smtplib\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from email.mime.text import MIMEText\n",
    "\n",
    "def format_json_pretty(data):\n",
    "    # Convert the data to a pretty-printed JSON string\n",
    "    return json.dumps(data, indent=4)\n",
    "\n",
    "def send_email(subject, body, to_email, from_email, smtp_server, smtp_port, smtp_username, smtp_password):\n",
    "    # Create a multipart message\n",
    "    msg = MIMEMultipart()\n",
    "    msg['From'] = from_email\n",
    "    msg['To'] = ', '.join(to_email)\n",
    "    msg['Subject'] = subject\n",
    "    \n",
    "    # Attach the body of the email\n",
    "    msg.attach(MIMEText(body, 'plain'))\n",
    "    \n",
    "    try:\n",
    "        # Create server object with SSL option\n",
    "        server = smtplib.SMTP_SSL(smtp_server, smtp_port)\n",
    "        server.login(smtp_username, smtp_password)\n",
    "        \n",
    "        # Send the email\n",
    "        server.sendmail(from_email, to_email, msg.as_string())\n",
    "        \n",
    "        # Disconnect from the server\n",
    "        server.quit()\n",
    "        \n",
    "        print(\"Email sent successfully!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to send email. Error: {str(e)}\")\n",
    "\n",
    "def main():\n",
    "    # Define the JSON file path\n",
    "    json_file = \"jobs.json\"\n",
    "    \n",
    "    # Get the current job postings from all companies\n",
    "    current_jobs = get_all_job_postings()\n",
    "    \n",
    "    # Load the previous job postings from the JSON file\n",
    "    previous_jobs = load_previous_jobs(json_file)\n",
    "    \n",
    "    # Identify new job postings\n",
    "    new_jobs = find_new_jobs(previous_jobs, current_jobs)\n",
    "    \n",
    "    # If new jobs are found, send an email notification\n",
    "    if new_jobs:\n",
    "        print(\"New job postings found:\")\n",
    "        \n",
    "        # Construct the email body\n",
    "        email_body = \"New job postings found:\\n\\n\"\n",
    "        for company, jobs in new_jobs.items():\n",
    "            email_body += f\"{company}:\\n\"\n",
    "            for job in jobs:\n",
    "                email_body += f\"{format_json_pretty(job)}\\n\"\n",
    "            email_body += \"\\n\"\n",
    "        \n",
    "        # Send the email\n",
    "        send_email(\n",
    "            subject=\"New Job Postings Alert\",\n",
    "            body=email_body,\n",
    "            to_email=[\"vaidehipatil2011@gmail.com\",\"barvepratik96@gmail.com\"],  # Replace with your email\n",
    "            from_email=\"barvepratik96@gmail.com\",  # Replace with your email\n",
    "            smtp_server=\"smtp.gmail.com\",  # Replace with your SMTP server\n",
    "            smtp_port=465,  # SMTP SSL port (e.g., 465 for Gmail)\n",
    "            smtp_username=\"barvepratik96@gmail.com\",  # Replace with your email username\n",
    "            smtp_password=\"qkgb oxdd etzu zqyj\"  # Replace with your email password\n",
    "        )\n",
    "        \n",
    "        # Print new jobs to the console as well\n",
    "        for company, jobs in new_jobs.items():\n",
    "            print(f\"\\n{company}:\")\n",
    "            for job in jobs:\n",
    "                print(job)\n",
    "    else:\n",
    "        print(\"No new job postings found.\")\n",
    "    \n",
    "    # Update the JSON file with the current job postings\n",
    "    update_json_file(json_file, current_jobs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No new job postings found.\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SETU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
